<!DOCTYPE html>
<html lang="en-us">
  <script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
  <head>
  <meta charset="UTF-8">
  <title>Deep Convolutoin Neural Network</title>
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="theme-color" content="#157878">
  <link rel="stylesheet" href="/css/normalize.css">
  <link href='https://fonts.googleapis.com/css?family=Open+Sans:400,700' rel='stylesheet' type='text/css'>
  <link rel="stylesheet" href="/css/cayman.css">
</head>

  <body>
    <section class="page-header">
  <h1 class="project-name">Deep Convolutoin Neural Network</h1>
  <h2 class="project-tagline"></h2>
  <!--
  <a href="#" class="btn">View on GitHub</a>
  <a href="#" class="btn">Download .zip</a>
  <a href="#" class="btn">Download .tar.gz</a>
  -->
</section>

    <section class="main-content">
      
      <h2>Machine Learning in Visual Recognition</h2>
<p class="meta">08 Jan 2017</p>

<h1>Introduce</h1>
<p>Machine Learning can be used in various different areas. In this project I’ll show how machine learing can be applied in the image recognition. Specifically, it will be introduced how the electricity meter will be automatically read. This project was implemented with OpenCV. Normally the gas or electricity meter looks like in the following figure.</p>
<div class="fig figcenter fighighlight">
  <img src="http://github.com/pages/keeperovswords/DeepConvolutionNetwork/assets/plate.png" width="50%" />
  <div class="figcaption">Electricity plate</div>
</div>

<p>Firstly the image area in yellow box will be detected, after it each single number image will be segmented. At last the number image will be classified. This is the basic concept. Now let’s go throught it out setp by step. In this project I’ll show the last part of this work as a image recognition task. The first and two parts belong to object detection and will be postponed in following blogs.</p>

<h1>Pipeline of Visual Recognition</h1>
<p>In the classical computer vision or OCR problem, we usually works as follows:</p>
<h2> Data preprocessing</h2>
<p>The training data (images) will be normlized, i.e. noise reduce, ratio adjustment etc. Ususally the images have different illumination, it can also be processed in this step. It requires the image processing approaches in this process.</p>

<h2> Feature Extraction</h2>
<p>After preprocessing the necessary information should be retained as much as possible, cause this information is very importent for training our models. The goal of feature extraction is to make the variablity of templates in the same classes minimized and maximied in different classes. In this prcoess the necessary knowledge of image processing should be required.</p>

<h2> Model Tranining</h2>
<p>The extracted relevant information will be used for training classification model. The machine learning models have different performance variously. So the model should be fairly evluated under some criteria.</p>

<p>The following sections will present each part of this pipeline and you’ll get a picture how this state of art process works separately.</p>


      <footer class="site-footer">
  <span class="site-footer-owner"><a href="http://localhost:4000">Deep Convolutoin Neural Network</a> is maintained by <a href="https://github.com/keeperovswords">Jian Xi</a>.</span>
  <span class="site-footer-credits">This page was generated by <a href="https://pages.github.com">GitHub Pages</a>.</span>
</footer>


    </section>

  </body>
</html>
